{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 Team 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, classification_report, confusion_matrix, recall_score\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "from itertools import islice\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "from pykernels import GeneralizedHistogramIntersection, RBF\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Read train and test files</h2>\n",
    "\n",
    "<h3>Functions:</h3>\n",
    "<ul>\n",
    "    <li><b>list_dir():</b> obtain the labels of the classes from the directory names.</li>\n",
    "    <li><b>get_label_path():</b> get paths of all the images of the dataset and their label.</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<h3>Variables:</h3>\n",
    "    <ul>\n",
    "    <i>listImages:</i> dictionary with the path of the images as keys and the class label as value.\n",
    "    <ul>\n",
    "    <li><b>train:</b> dictionary of train subdivision.</li>\n",
    "    <li><b>test:</b> dictionary of test subdiviosn.</li>\n",
    "    </ul></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {}\n",
    "\n",
    "paths['trainImages'] = \"./train/\"\n",
    "paths['testImages'] = \"./test/\"\n",
    "\n",
    "def list_dir(path_dir):\n",
    "    f = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(path_dir):\n",
    "        f.extend(dirnames)\n",
    "        break\n",
    "    return f\n",
    "\n",
    "def get_label_path(path_dir):\n",
    "    path_label = list_dir(path_dir)\n",
    "    listImages ={}\n",
    "     \n",
    "    for label in path_label:\n",
    "        \n",
    "        # Import Data from directories\n",
    "        for filename in os.listdir(path_dir + label):\n",
    "            if filename.endswith(\".jpg\"):\n",
    "                listImages[path_dir + label + '/'+ filename] = label\n",
    "    return listImages\n",
    "\n",
    "def getData():\n",
    "    train = get_label_path(paths['trainImages'])\n",
    "    test = get_label_path(paths['testImages'])\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Cross Validation Variant</H3>\n",
    "\n",
    "In order to avoid depending on a correct selection of the train and test data sets, we used cross validation technique.    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IN: Train samples, number of splits\n",
    "#OUT: Train and validation batches\n",
    "def crossValidation(train, splits=2):\n",
    "    X = np.array(list(train.keys()))\n",
    "    y = np.array(list(train.values()))\n",
    "    \n",
    "    X_train = []\n",
    "    X_validation = []\n",
    "    y_train = []\n",
    "    y_validation = []\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=splits)\n",
    "    for train_index, validation_index in skf.split(X, y):\n",
    "        X_train.append(X[train_index])\n",
    "        X_validation.append(X[validation_index])\n",
    "        y_train.append(y[train_index])\n",
    "        y_validation.append(y[validation_index])\n",
    "\n",
    "    return X_train, y_train, X_validation, y_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create SIFT object detector and descriptor</h2>\n",
    "We compute the SIFT descriptors for all the train images and subsequently build a numpy array with all the descriptors stacked together.\n",
    "\n",
    "<h3>Function:</h3>\n",
    "<ul>\n",
    "    <li><b>numFeaturesIteration():</b> reads the image, converting it to gray, and applies the SIFT detector to fins the descriptors of the image.</li>\n",
    "</ul>\n",
    "\n",
    "<h3>Variables:</h3>\n",
    "<ul>\n",
    "    <li><b>Train_descriptors:</b> list of all the descriptors of each image.</li>\n",
    "    <li><b>D:</b> stack of the descriptors of all the images.</li>\n",
    "    <li><b>SIFTdescriptor:</b> class for extracting keypoints and computing descriptors using SIFT.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IN: Number of features\n",
    "# OUT: Sift Object\n",
    "def createSift(numFeatures=0):\n",
    "    sift = cv2.xfeatures2d.SIFT_create(nfeatures=numFeatures)\n",
    "    return sift\n",
    "\n",
    "\n",
    "# IN: Image, SIFT\n",
    "# OUT: Descriptor of Image\n",
    "def siftDescriptors(image, sift):\n",
    "    _, des = sift.detectAndCompute(image, None)\n",
    "    return des\n",
    "\n",
    "\n",
    "# IN: Image, SIFT, Sclae, Step\n",
    "# OUT: Descriptor of Image\n",
    "def denseSiftDescriptors(image, sift, scale, step):\n",
    "    kps = []\n",
    "    for x in range(0, image.shape[1], step):\n",
    "        for y in range(0, image.shape[0], step):\n",
    "            if (scale == 0):\n",
    "                scale = step * random.uniform(1, 3)\n",
    "            kp = cv2.KeyPoint(x, y, scale)\n",
    "            kps.append(kp)\n",
    "    _, des = sift.compute(image, kps)\n",
    "    return des\n",
    "\n",
    "\n",
    "# IN: Descriptor numpy array\n",
    "# OUT: Descriptor Stacked list\n",
    "def stackDescriptors(descriptorsList):\n",
    "    stackedDescriptors = np.vstack(descriptorsList)\n",
    "    return stackedDescriptors\n",
    "\n",
    "\n",
    "# IN: Dictionary of Images and Labels\n",
    "# OUT: Descriptor Stacked List\n",
    "def getDescriptors(X_Data, sift, isPca=False, isDense=False, scale=0, step=0):\n",
    "    descriptors = []\n",
    "    for filename in X_Data:\n",
    "        ima = cv2.imread(filename)\n",
    "        gray = cv2.cvtColor(ima, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if(isDense):\n",
    "            des = denseSiftDescriptors(gray, sift, scale, step)\n",
    "        else:\n",
    "            des = siftDescriptors(gray, sift)\n",
    "        if (isPca):\n",
    "            descriptors.append(dimensionalityReduction(des, 2))\n",
    "        else:\n",
    "            descriptors.append(des)\n",
    "    D = stackDescriptors(descriptors)\n",
    "    return D, descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Spatial Pyramids</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageFeaturesSPM(L, sets, codebook, sift, k):\n",
    "    visual_words = []\n",
    "    for filename in sets:\n",
    "        ima = cv2.imread(filename)\n",
    "        img = cv2.cvtColor(ima, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        W = img.shape[1]\n",
    "        H = img.shape[0]\n",
    "        h = []\n",
    "        for l in range(L + 1):\n",
    "            w_step = math.floor(W / (2 ** l))\n",
    "            h_step = math.floor(H / (2 ** l))\n",
    "            x, y = 0, 0\n",
    "            for i in range(1, 2 ** l + 1):\n",
    "                x = 0\n",
    "                for j in range(1, 2 ** l + 1):\n",
    "                    desc = denseSiftDescriptors(img[y:int(y + h_step), x:int(x + w_step)], sift, scale, step)\n",
    "                    list_des = [desc]\n",
    "                    predict = predictDescriptorsClusters(list_des, codebook, k)\n",
    "                    histo = predict.ravel()\n",
    "                    weight = 2 ** (l - L)\n",
    "                    h.append(weight * histo)\n",
    "                    x = int(x + w_step)\n",
    "                y = int(y + h_step)\n",
    "\n",
    "        hist = np.array(h).ravel()\n",
    "        # normalize hist\n",
    "        dev = np.std(hist)\n",
    "        hist -= np.mean(hist)\n",
    "        hist /= dev\n",
    "        visual_words.append(hist)\n",
    "    return visual_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> Declare Representation Spaces</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimensionalityReduction(parsedDescriptors, numComponents=2):\n",
    "    parsedDescriptors = np.transpose(parsedDescriptors)\n",
    "    pca = PCA(n_components=numComponents)\n",
    "    pca.fit(parsedDescriptors)\n",
    "    reducedParsedDescriptors = pca.components_\n",
    "    reducedParsedDescriptors = np.transpose(reducedParsedDescriptors)\n",
    "    return reducedParsedDescriptors\n",
    "\n",
    "\n",
    "def setRepresentationSpaceCentroids(parsedDescriptors, numClusters = 128):\n",
    "    codebook = MiniBatchKMeans(n_clusters=numClusters, verbose=False, batch_size=numClusters * 20,compute_labels=False,\n",
    "                               reassignment_ratio=10**-4, random_state=42)\n",
    "    codebook.fit(parsedDescriptors)\n",
    "    return codebook\n",
    "\n",
    "\n",
    "def predictDescriptorsClusters(descriptorsList, codebook, numClusters=128):\n",
    "    visual_words = np.zeros((len(descriptorsList), numClusters), dtype=np.float32)\n",
    "    for i in range(len(descriptorsList)):\n",
    "        words = codebook.predict(descriptorsList[i])\n",
    "        visual_words[i, :] = np.bincount(words, minlength=numClusters)\n",
    "    return visual_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Predict Data</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleData(data):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    return scaled_data\n",
    "\n",
    "def LinearSVM(y_train_Split, visual_words):\n",
    "    scaled_visual_words = scaleData(visual_words)\n",
    "    lsvm = LinearSVC()\n",
    "    lsvm.fit(visual_words, list(y_train_Split))\n",
    "    return lsvm\n",
    "\n",
    "def rbfSVM(y_train_Split, visual_words):\n",
    "    scaled_visual_words = scaleData(visual_words)\n",
    "    rbf_svm = SVC(kernel=RBF())\n",
    "    rbf_svm.fit(visual_words, list(y_train_Split))\n",
    "    return rbf_svm\n",
    "\n",
    "def histIntersectionSVM(y_train_Split, visual_words):\n",
    "    scaled_visual_words = scaleData(visual_words)\n",
    "    rbf_svm = SVC(kernel=GeneralizedHistogramIntersection())\n",
    "    rbf_svm.fit(visual_words, list(y_train_Split))\n",
    "    return rbf_svm\n",
    "\n",
    "def fitNearestNeighbours(y_train_Split, numNeighbours, visual_words, metric):\n",
    "    knn = KNeighborsClassifier(n_neighbors=numNeighbours,n_jobs=-1,metric=metric)\n",
    "    knn.fit(visual_words, list(y_train_Split))\n",
    "    return knn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Metrics Of Evaluations</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(y_validation_Split, classifier, visual_words):\n",
    "    accuracy = 100 * classifier.score(visual_words, list(y_validation_Split))\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def getPrecision(y_validation_Split, visual_words):\n",
    "    precision = precision_score(list(y_validation_Split), visual_words)\n",
    "    return precision\n",
    "\n",
    "\n",
    "def getRecall(y_validation_Split, visual_words):\n",
    "    recall = recall_score(list(y_validation_Split), visual_words)\n",
    "    return recall\n",
    "\n",
    "\n",
    "def getF1Score(visual_words):\n",
    "    precision = getPrecision(visual_words)\n",
    "    recall = getRecall(visual_words)\n",
    "    F1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Start Sequency of operations </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Obtain Descriptors</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllDescriptors(X_train_Split, X_validation_Split, isPca, isDense, numFeatures, scale, step):\n",
    "    if (isDense):\n",
    "        numFeatures = 0\n",
    "    sift = createSift(numFeatures)\n",
    "    D_train, desciptors_train = getDescriptors(X_train_Split, sift, isPca, isDense, scale, step)\n",
    "    D_test, desciptors_test = getDescriptors(X_validation_Split, sift, isPca, isDense, scale, step)\n",
    "    return D_train, D_test, desciptors_train, desciptors_test, sift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Train Cluster</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainedCluster(y_train_Split, D, numClusters, descriptors, numNeighbours, distanceMetric, classifier):\n",
    "    codebook = setRepresentationSpaceCentroids(D, numClusters)\n",
    "    visual_words = predictDescriptorsClusters(descriptors, codebook, numClusters)\n",
    "    if (classifier == \"KNN\"):\n",
    "        knn = fitNearestNeighbours(y_train_Split, numNeighbours, visual_words, distanceMetric)\n",
    "    elif (classifier == \"LinearSVM\"):\n",
    "        knn = LinearSVM(y_train_Split, visual_words)\n",
    "    elif (classifier == \"RBFSVM\"):\n",
    "        knn = rbfSVM(y_train_Split, visual_words)\n",
    "    elif (classifier == \"Hist\"):\n",
    "        knn = histIntersectionSVM(y_train_Split, visual_words)\n",
    "    else:\n",
    "        print(classifier, \" Is undefinied.\")\n",
    "    return codebook, knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Predict With Test</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResults(y_validation_Split, knn, descriptorsTest, codebook, numClusters):\n",
    "    visual_words_test = predictDescriptorsClusters(descriptorsTest, codebook, numClusters)\n",
    "    accuracy = getAccuracy(y_validation_Split, knn, visual_words_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Main Pipeline of executions </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(classifier, isDense, isPca, numClusters, numNeighbours, scale, step, distanceMetric, numFeatures, splits):\n",
    "    train, test = getData()\n",
    "    X_train, y_train, X_validation, y_validation = crossValidation(train, splits)\n",
    "    accuracy = 0\n",
    "    accuracy_SPM = 0\n",
    "    for X_train_Split, y_train_Split, X_validation_Split, y_validation_Split in zip(X_train, y_train, X_validation,\n",
    "                                                                                    y_validation):\n",
    "        D_train, D_test, descriptors_train, descriptors_test, sift = getAllDescriptors(X_train_Split, X_validation_Split,\n",
    "                                                                                 isPca, isDense, numFeatures, scale, step)\n",
    "\n",
    "        codebook, knn = getTrainedCluster(y_train_Split, D_train, numClusters, descriptors_train, numNeighbours, distanceMetric,\n",
    "                                          classifier)\n",
    "\n",
    "        accuracy = accuracy + getResults(y_validation_Split, knn, descriptors_test, codebook, numClusters)\n",
    "\n",
    "        train_histo = getImageFeaturesSPM(pyramid_levels, X_train_Split, codebook, sift, numClusters)\n",
    "        test_histo = getImageFeaturesSPM(pyramid_levels, X_validation_Split, codebook, sift, numClusters)\n",
    "        if (classifier == \"KNN\"):\n",
    "            knn = fitNearestNeighbours(y_train_Split, numNeighbours, train_histo, distanceMetric)\n",
    "        elif (classifier == \"LinearSVM\"):\n",
    "            knn = LinearSVM(y_train_Split, train_histo)\n",
    "        elif (classifier == \"RBFSVM\"):\n",
    "            knn = rbfSVM(y_train_Split, train_histo)\n",
    "        elif (classifier == \"Hist\"):\n",
    "            knn = histIntersectionSVM(y_train_Split, train_histo)\n",
    "        else:\n",
    "            print(classifier, \" Is undefinied.\")\n",
    "\n",
    "        accuracy_SPM = accuracy_SPM + getAccuracy(y_validation_Split, knn, test_histo)\n",
    "\n",
    "    return accuracy / splits, accuracy_SPM/splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68.79225360074163, 74.79950030524341)\n"
     ]
    }
   ],
   "source": [
    "classifier = \"Hist\"\n",
    "isDense = True\n",
    "isPca = False\n",
    "numClusters = 96\n",
    "numNeighbours = 27\n",
    "scale = 2\n",
    "step = 16\n",
    "distanceMetric = \"euclidean\"\n",
    "numFeatures = 0\n",
    "splits = 2\n",
    "pyramid_levels = 2\n",
    "print( main(classifier, isDense, isPca, numClusters, numNeighbours, scale, step, distanceMetric, numFeatures, splits))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Compute a k-means clustering on the descriptor space</h2>\n",
    "\n",
    "<h3>Function:</h3>\n",
    "<ul>\n",
    "    <li><b>numClustersIteration():</b> for each train image, projects each keypoint descriptor to its closest visual word.\n",
    "    Each of the images is represented with the frequency of each visual word.</li>\n",
    "</ul>\n",
    "\n",
    "<h3>Variables:</h3>\n",
    "<ul>\n",
    "    <li><b>visual_words:</b> frequency list of all the visual words of the images.</li>\n",
    "    <li><b>codebook:</b> K-means algorithm implementation with a restricted batch size.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Build and train a k-nn classifier</h2>\n",
    "\n",
    "<h3>Function:</h3>\n",
    "<ul>\n",
    "    <li><b>numNeighIteration():</b> creates a k-nn classifier and trains it with the train descriptors. Then computes the test descriptors and the accuracy of the model.</li>\n",
    "</ul>\n",
    "\n",
    "<h3>Variables:</h3>\n",
    "<ul>\n",
    "    <li><b>knn:</b> K Nearest Neighbors classifier with the neighbors and metric specified.</li>\n",
    "    <li><b>visual_words_test:</b> resulting classification of the algorithm for all the images.</li>\n",
    "    <li><b>mat_accuracy:</b> accuracy for the different combinations of metrics(k-nn), number of neighbors(k-nn), number of features(SIFT) and number of clusters(k-means).\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3D Results</h2>\n",
    "We have executed the code changing the values of the following variables:\n",
    "<ul>\n",
    "    <li><b>k:</b> number of clusters of the k-means algorithm. [2<sup>4</sup>, 2<sup>5</sup>, 2<sup>6</sup>, 2<sup>7</sup>]</li>\n",
    "    <li><b>neigh:</b> number of neighbours to compare to in the k-nn algorithm. [24, 27, 30, 33]</li>\n",
    "    <li><b>numFeatures:</b> number of features to take from the SIFT detector. [60, 120, 180, 240]</li>\n",
    "    <li><b>metric:</b> distance metric to calculate distances from classes on the k-nn algorithm. [euclidean, manhattan, chebyshev, minkowski]</li>\n",
    "</ul>\n",
    "\n",
    "The results are ploted as 3D accuracy plots for each number of clusters and features independently with a set of neighbour quantities (X axis) and distance metrics (Y axis).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best results for number of <i>neighbours</i> was found at <b>30</b>, the ideal number of <i>clusters</i> was arround <b>96</b> with the <b>euclidean</b> <i>metric</i> and the number of <i>features</i> arround <b>300</b>.\n",
    "<br>\n",
    "It has to be taken into account that not all possible values of those variables were tried though a better result might exist within the non-tested combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2D results</h2>\n",
    "To find a most accurate parameters solution we execute the algorithm fixing 3 of the 4 parameters and iterating for a set of values of the other variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Unary Parameter Dependent</h3>\n",
    "\n",
    "In order to compute the high time complexity emprovements, we implemented a method that only expect to return a unical result given the best combination of parameters, that will help us to manage the results of the Dense SIFT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1> Dense Sift Emprovement</H1>\n",
    "The difference between SIFT and Dense SIFT is that with dense SIFT you get a  descriptor at every location, while with normal SIFT you get a descriptions at the locations determined by Lowe's algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Dense Sift Findings</H3>\n",
    "\n",
    "As we can see given the best combination of the obtained parameters of the SIFT descriptor already tested, Dense Sift descriptors performs way better, since in SIFT descriptors, the focus is to find the more representative points of the image regardless that most of them are close to each other. So in Dense SIFT descriptors as all the points are sequentially spotted, the information of the less relevant areas of the landscapes are not lost, and you can match easily those landscapes that have low energy frequencies in most of the image but from one small area with others of the same type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
